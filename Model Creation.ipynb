{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1660.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>0.692857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.055783</td>\n",
       "      <td>26.258952</td>\n",
       "      <td>...</td>\n",
       "      <td>48.765331</td>\n",
       "      <td>63.902279</td>\n",
       "      <td>0.326692</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.445602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>44.428330</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1660.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>0.692857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.055783</td>\n",
       "      <td>26.258952</td>\n",
       "      <td>...</td>\n",
       "      <td>48.765331</td>\n",
       "      <td>63.902279</td>\n",
       "      <td>0.326692</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.445602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>44.428330</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1660.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>0.692857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.055783</td>\n",
       "      <td>26.258952</td>\n",
       "      <td>...</td>\n",
       "      <td>31.103462</td>\n",
       "      <td>45.165862</td>\n",
       "      <td>0.621176</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.838969</td>\n",
       "      <td>0.100242</td>\n",
       "      <td>33.628019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1660.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>0.692857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.055783</td>\n",
       "      <td>26.258952</td>\n",
       "      <td>...</td>\n",
       "      <td>31.103462</td>\n",
       "      <td>45.165862</td>\n",
       "      <td>0.621176</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.838969</td>\n",
       "      <td>0.100242</td>\n",
       "      <td>33.628019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1549.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.092857</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>35.036562</td>\n",
       "      <td>48.044634</td>\n",
       "      <td>0.556505</td>\n",
       "      <td>0.063628</td>\n",
       "      <td>0.189934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.840931</td>\n",
       "      <td>0.121083</td>\n",
       "      <td>33.346154</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1         2         3         4          5         6   \\\n",
       "0  1660.000000  12.000000  5.333333  5.666667  1.000000  12.333333  0.692857   \n",
       "1  1660.000000  12.000000  5.333333  5.666667  1.000000  12.333333  0.692857   \n",
       "2  1660.000000  12.000000  5.333333  5.666667  1.000000  12.333333  0.692857   \n",
       "3  1660.000000  12.000000  5.333333  5.666667  1.000000  12.333333  0.692857   \n",
       "4  1549.666667   2.333333  0.666667  1.000000  0.666667   6.666667  0.259259   \n",
       "\n",
       "    7          8          9   ...         49         50        51        52  \\\n",
       "0  0.0  13.055783  26.258952  ...  48.765331  63.902279  0.326692  0.087500   \n",
       "1  0.0  13.055783  26.258952  ...  48.765331  63.902279  0.326692  0.087500   \n",
       "2  0.0  13.055783  26.258952  ...  31.103462  45.165862  0.621176  0.014493   \n",
       "3  0.0  13.055783  26.258952  ...  31.103462  45.165862  0.621176  0.014493   \n",
       "4  0.0  12.092857  18.333333  ...  35.036562  48.044634  0.556505  0.063628   \n",
       "\n",
       "         53   54        55        56         57  58  \n",
       "0  0.445602  0.0  0.974359  0.025641  44.428330   0  \n",
       "1  0.445602  0.0  0.974359  0.025641  44.428330   0  \n",
       "2  0.009259  0.0  0.838969  0.100242  33.628019   0  \n",
       "3  0.009259  0.0  0.838969  0.100242  33.628019   0  \n",
       "4  0.189934  0.0  0.840931  0.121083  33.346154   1  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('data_creation/training_data.csv', header=None)\n",
    "train_X = train_data[train_data.columns[:-1]]\n",
    "train_y = train_data[train_data.columns[-1]]\n",
    "test_data = pd.read_csv('data_creation/test_data.csv', header=None)\n",
    "test_X = test_data[test_data.columns[:-1]]\n",
    "test_y = test_data[test_data.columns[-1]]\n",
    "#print(f\"Training dataset size: {len(train_X.index)}\")\n",
    "#print(f\"Test dataset size: {len(test_X.index)}\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to lists\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for X, y, data in ((X_train, y_train, train_data), (X_test, y_test, test_data)):\n",
    "    for idx in data.index:\n",
    "        row = list(data.iloc[idx])\n",
    "        X.append(row[:-1])\n",
    "        y.append(row[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16434 58\n",
      "16434\n",
      "1588 58\n",
      "1588\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_train[0]))\n",
    "print(len(y_train))\n",
    "\n",
    "print(len(X_test), len(X_test[0]))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=250,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=250)\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy: 0.7562972292191436\n"
     ]
    }
   ],
   "source": [
    "print(f\"Acuracy: {random_forest.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 512)               30208     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 161,793\n",
      "Trainable params: 161,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(58,)))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(momentum = 0.3, learning_rate=0.1)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 58)                3422      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1888      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 8,511\n",
      "Trainable params: 8,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(58, activation=tf.nn.relu, input_shape=(58,)))\n",
    "model.add(tf.keras.layers.Dense(32, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(32, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(32, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(32, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(momentum = 0.3, learning_rate=0.1)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16434 samples, validate on 1588 samples\n",
      "Epoch 1/50\n",
      "16434/16434 [==============================] - 5s 303us/sample - loss: 0.8313 - accuracy: 0.7212 - val_loss: 0.6593 - val_accuracy: 0.7059\n",
      "Epoch 2/50\n",
      "16434/16434 [==============================] - 3s 179us/sample - loss: 0.6077 - accuracy: 0.7267 - val_loss: 0.4464 - val_accuracy: 0.7733\n",
      "Epoch 3/50\n",
      "16434/16434 [==============================] - 3s 202us/sample - loss: 0.5537 - accuracy: 0.7388 - val_loss: 0.6069 - val_accuracy: 0.7084\n",
      "Epoch 4/50\n",
      "16434/16434 [==============================] - 4s 215us/sample - loss: 0.5235 - accuracy: 0.7463 - val_loss: 0.4342 - val_accuracy: 0.7827\n",
      "Epoch 5/50\n",
      "16434/16434 [==============================] - 4s 217us/sample - loss: 0.5080 - accuracy: 0.7503 - val_loss: 0.4360 - val_accuracy: 0.7815\n",
      "Epoch 6/50\n",
      "16434/16434 [==============================] - 4s 228us/sample - loss: 0.4981 - accuracy: 0.7555 - val_loss: 0.4467 - val_accuracy: 0.7783\n",
      "Epoch 7/50\n",
      "16434/16434 [==============================] - 4s 216us/sample - loss: 0.4989 - accuracy: 0.7540 - val_loss: 0.4413 - val_accuracy: 0.7878\n",
      "Epoch 8/50\n",
      "16434/16434 [==============================] - 4s 231us/sample - loss: 0.4910 - accuracy: 0.7601 - val_loss: 0.4338 - val_accuracy: 0.7853\n",
      "Epoch 9/50\n",
      "16434/16434 [==============================] - 4s 247us/sample - loss: 0.5150 - accuracy: 0.7491 - val_loss: 0.4523 - val_accuracy: 0.7727\n",
      "Epoch 10/50\n",
      "16434/16434 [==============================] - 4s 224us/sample - loss: 0.4889 - accuracy: 0.7583 - val_loss: 0.5090 - val_accuracy: 0.7273\n",
      "Epoch 11/50\n",
      "16434/16434 [==============================] - 3s 201us/sample - loss: 0.4883 - accuracy: 0.7617 - val_loss: 0.4490 - val_accuracy: 0.7746\n",
      "Epoch 12/50\n",
      "16434/16434 [==============================] - 4s 229us/sample - loss: 0.4809 - accuracy: 0.7646 - val_loss: 0.4569 - val_accuracy: 0.7790\n",
      "Epoch 13/50\n",
      "16434/16434 [==============================] - 3s 213us/sample - loss: 0.4856 - accuracy: 0.7627 - val_loss: 0.4391 - val_accuracy: 0.7878\n",
      "Epoch 14/50\n",
      "16434/16434 [==============================] - 3s 213us/sample - loss: 0.4861 - accuracy: 0.7637 - val_loss: 0.5208 - val_accuracy: 0.7393\n",
      "Epoch 15/50\n",
      "16434/16434 [==============================] - 4s 249us/sample - loss: 0.4821 - accuracy: 0.7664 - val_loss: 0.5669 - val_accuracy: 0.7179\n",
      "Epoch 16/50\n",
      "16434/16434 [==============================] - 4s 230us/sample - loss: 0.4848 - accuracy: 0.7645 - val_loss: 0.4349 - val_accuracy: 0.7909\n",
      "Epoch 17/50\n",
      "16434/16434 [==============================] - 4s 241us/sample - loss: 0.4822 - accuracy: 0.7668 - val_loss: 0.4440 - val_accuracy: 0.7827\n",
      "Epoch 18/50\n",
      "16434/16434 [==============================] - 4s 239us/sample - loss: 0.4869 - accuracy: 0.7599 - val_loss: 0.4550 - val_accuracy: 0.7777\n",
      "Epoch 19/50\n",
      "16434/16434 [==============================] - 4s 224us/sample - loss: 0.4827 - accuracy: 0.7670 - val_loss: 0.4329 - val_accuracy: 0.7878\n",
      "Epoch 20/50\n",
      "16434/16434 [==============================] - 4s 234us/sample - loss: 0.4802 - accuracy: 0.7646 - val_loss: 0.4419 - val_accuracy: 0.7865\n",
      "Epoch 21/50\n",
      "16434/16434 [==============================] - 4s 242us/sample - loss: 0.4772 - accuracy: 0.7675 - val_loss: 0.4939 - val_accuracy: 0.7689\n",
      "Epoch 22/50\n",
      "16434/16434 [==============================] - 4s 245us/sample - loss: 0.4804 - accuracy: 0.7671 - val_loss: 0.4322 - val_accuracy: 0.7846\n",
      "Epoch 23/50\n",
      "16434/16434 [==============================] - 4s 226us/sample - loss: 0.4791 - accuracy: 0.7642 - val_loss: 0.4737 - val_accuracy: 0.7727\n",
      "Epoch 24/50\n",
      "16434/16434 [==============================] - 4s 261us/sample - loss: 0.4747 - accuracy: 0.7708 - val_loss: 0.4907 - val_accuracy: 0.7651\n",
      "Epoch 25/50\n",
      "16434/16434 [==============================] - 5s 277us/sample - loss: 0.4770 - accuracy: 0.7699 - val_loss: 0.4617 - val_accuracy: 0.7783\n",
      "Epoch 26/50\n",
      "16434/16434 [==============================] - 4s 262us/sample - loss: 0.4766 - accuracy: 0.7688 - val_loss: 0.4741 - val_accuracy: 0.7720\n",
      "Epoch 27/50\n",
      "16434/16434 [==============================] - 4s 263us/sample - loss: 0.4729 - accuracy: 0.7708 - val_loss: 0.4523 - val_accuracy: 0.7739\n",
      "Epoch 28/50\n",
      "16434/16434 [==============================] - 3s 179us/sample - loss: 0.4762 - accuracy: 0.7654 - val_loss: 0.4369 - val_accuracy: 0.7909\n",
      "Epoch 29/50\n",
      "16434/16434 [==============================] - 3s 178us/sample - loss: 0.4741 - accuracy: 0.7719 - val_loss: 0.4727 - val_accuracy: 0.7613\n",
      "Epoch 30/50\n",
      "16434/16434 [==============================] - 3s 172us/sample - loss: 0.4758 - accuracy: 0.7693 - val_loss: 0.4374 - val_accuracy: 0.7872\n",
      "Epoch 31/50\n",
      "16434/16434 [==============================] - 3s 166us/sample - loss: 0.4704 - accuracy: 0.7709 - val_loss: 0.4395 - val_accuracy: 0.7846\n",
      "Epoch 32/50\n",
      "16434/16434 [==============================] - 3s 169us/sample - loss: 0.4700 - accuracy: 0.7733 - val_loss: 0.4466 - val_accuracy: 0.7758\n",
      "Epoch 33/50\n",
      "16434/16434 [==============================] - 2s 136us/sample - loss: 0.4716 - accuracy: 0.7730 - val_loss: 0.4561 - val_accuracy: 0.7771\n",
      "Epoch 34/50\n",
      "16434/16434 [==============================] - 2s 133us/sample - loss: 0.4717 - accuracy: 0.7695 - val_loss: 0.4477 - val_accuracy: 0.7809\n",
      "Epoch 35/50\n",
      "16434/16434 [==============================] - 2s 139us/sample - loss: 0.4708 - accuracy: 0.7699 - val_loss: 0.4372 - val_accuracy: 0.7928\n",
      "Epoch 36/50\n",
      "16434/16434 [==============================] - 2s 140us/sample - loss: 0.4707 - accuracy: 0.7718 - val_loss: 0.4526 - val_accuracy: 0.7790\n",
      "Epoch 37/50\n",
      "16434/16434 [==============================] - 3s 159us/sample - loss: 0.4711 - accuracy: 0.7730 - val_loss: 0.4637 - val_accuracy: 0.7764\n",
      "Epoch 38/50\n",
      "16434/16434 [==============================] - 2s 131us/sample - loss: 0.4706 - accuracy: 0.7735 - val_loss: 0.4374 - val_accuracy: 0.7878\n",
      "Epoch 39/50\n",
      "16434/16434 [==============================] - 2s 136us/sample - loss: 0.4698 - accuracy: 0.7731 - val_loss: 0.4552 - val_accuracy: 0.7733\n",
      "Epoch 40/50\n",
      "16434/16434 [==============================] - 2s 131us/sample - loss: 0.4689 - accuracy: 0.7749 - val_loss: 0.4389 - val_accuracy: 0.7853\n",
      "Epoch 41/50\n",
      "16434/16434 [==============================] - 2s 138us/sample - loss: 0.4689 - accuracy: 0.7746 - val_loss: 0.4401 - val_accuracy: 0.7865\n",
      "Epoch 42/50\n",
      "16434/16434 [==============================] - 2s 118us/sample - loss: 0.4720 - accuracy: 0.7711 - val_loss: 0.4612 - val_accuracy: 0.7764\n",
      "Epoch 43/50\n",
      "16434/16434 [==============================] - 2s 125us/sample - loss: 0.4698 - accuracy: 0.7734 - val_loss: 0.4467 - val_accuracy: 0.7890\n",
      "Epoch 44/50\n",
      "16434/16434 [==============================] - 2s 123us/sample - loss: 0.4689 - accuracy: 0.7743 - val_loss: 0.4364 - val_accuracy: 0.7865\n",
      "Epoch 45/50\n",
      "16434/16434 [==============================] - 2s 121us/sample - loss: 0.4690 - accuracy: 0.7746 - val_loss: 0.4832 - val_accuracy: 0.7487\n",
      "Epoch 46/50\n",
      "16434/16434 [==============================] - 2s 133us/sample - loss: 0.4698 - accuracy: 0.7725 - val_loss: 0.4392 - val_accuracy: 0.7846\n",
      "Epoch 47/50\n",
      "16434/16434 [==============================] - 2s 115us/sample - loss: 0.4711 - accuracy: 0.7713 - val_loss: 0.4665 - val_accuracy: 0.7733\n",
      "Epoch 48/50\n",
      "16434/16434 [==============================] - 2s 115us/sample - loss: 0.4690 - accuracy: 0.7736 - val_loss: 0.4385 - val_accuracy: 0.7884\n",
      "Epoch 49/50\n",
      "16434/16434 [==============================] - 2s 114us/sample - loss: 0.4691 - accuracy: 0.7751 - val_loss: 0.4379 - val_accuracy: 0.7859\n",
      "Epoch 50/50\n",
      "16434/16434 [==============================] - 2s 108us/sample - loss: 0.4692 - accuracy: 0.7753 - val_loss: 0.4377 - val_accuracy: 0.7903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f13f4c42630>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 50\n",
    "model.fit(X_train, y_train, epochs=NUM_EPOCHS, validation_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
